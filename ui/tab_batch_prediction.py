import streamlit as st
import pandas as pd
import numpy as np

# We need the summary function
from ui.utils import generate_shap_summary

def display_batch_prediction_tab():
    """
    Displays the UI for the Batch Analysis tab.
    """
    st.header("ğŸ—‚ï¸ æ‰¹æ¬¡æµé‡åˆ†æ")

    if 'selected_features' not in st.session_state:
        st.warning("æ¨¡å‹å°šæœªè¼‰å…¥æˆ–è¨“ç·´ï¼Œç„¡æ³•é€²è¡Œæ‰¹æ¬¡åˆ†æã€‚")
        return

    st.write("ä¸Šå‚³åŒ…å«å¤šç­†ç¶²è·¯æµé‡çš„ CSV æª”ï¼Œç³»çµ±å°‡é€ç­†åˆ†æä¸¦åˆ¤æ–·æ˜¯å¦ç‚ºæ”»æ“Šã€‚")

    # --- Template Download ---
    template_df = pd.DataFrame(columns=st.session_state['selected_features'])
    csv_template = template_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="ä¸‹è¼‰åˆ†æç¯„ä¾‹ CSV æª”æ¡ˆ",
        data=csv_template,
        file_name="prediction_template.csv",
        mime="text/csv",
    )

    # --- File Uploader ---
    uploaded_file = st.file_uploader("ä¸Šå‚³å¾…åˆ†æçš„ CSV æª”æ¡ˆ", type=["csv"])

    if uploaded_file is not None:
        # Clear previous results if a new file is uploaded
        if 'current_file_name' not in st.session_state or st.session_state.current_file_name != uploaded_file.name:
            st.session_state.current_file_name = uploaded_file.name
            if 'batch_results_df' in st.session_state:
                del st.session_state['batch_results_df']

        try:
            batch_df_raw = pd.read_csv(uploaded_file)
            batch_df_raw.replace([np.inf, -np.inf], np.nan, inplace=True)
            
            with st.expander("é»æ­¤æŸ¥çœ‹ä¸Šå‚³çš„åŸå§‹è³‡æ–™ (å‰ 5 ç­†)"):
                st.dataframe(batch_df_raw.head())

            # --- Column Mapping ---
            uploaded_columns = batch_df_raw.columns.tolist()
            st.subheader("æ¬„ä½æ˜ å°„è¨­å®š")
            column_mapping = {}
            mapping_cols = st.columns(4)
            for i, feature in enumerate(st.session_state['selected_features']):
                with mapping_cols[i % 4]:
                    default_index = uploaded_columns.index(feature) + 1 if feature in uploaded_columns else 0
                    column_mapping[feature] = st.selectbox(
                        f"æ¨¡å‹ç‰¹å¾µ: {feature}",
                        ['æœªæ˜ å°„'] + uploaded_columns,
                        index=default_index,
                        key=f"map_{feature}"
                    )
            
            # --- Run Analysis ---
            if st.button("ğŸš€ é–‹å§‹åˆ†ææµé‡"):
                with st.spinner("æ­£åœ¨æ ¹æ“šæ˜ å°„è¨­å®šè™•ç†è³‡æ–™ä¸¦é€²è¡Œåˆ†æ..."):
                    # Create a DataFrame with the correct feature columns
                    batch_X_mapped_user = pd.DataFrame(0.0, index=batch_df_raw.index, columns=st.session_state['selected_features'])
                    for model_feature, uploaded_col in column_mapping.items():
                        if uploaded_col != 'æœªæ˜ å°„':
                            batch_X_mapped_user[model_feature] = pd.to_numeric(batch_df_raw[uploaded_col], errors='coerce')
                    
                    batch_X_mapped_user.replace([np.inf, -np.inf], np.nan, inplace=True)
                    batch_X_mapped_user.dropna(inplace=True)

                    if batch_X_mapped_user.empty:
                        st.warning("é è™•ç†å¾Œï¼Œä¸Šå‚³æª”æ¡ˆä¸­æ²’æœ‰æœ‰æ•ˆè³‡æ–™å¯ä¾›åˆ†æã€‚")
                        if 'batch_results_df' in st.session_state:
                            del st.session_state['batch_results_df']
                    else:
                        scaler = st.session_state['scaler']
                        model = st.session_state['trained_model']
                        le = st.session_state['le']

                        required_features_for_scaler = scaler.feature_names_in_
                        batch_df_full = pd.DataFrame(0.0, index=batch_X_mapped_user.index, columns=required_features_for_scaler)
                        
                        for col in batch_X_mapped_user.columns:
                            if col in batch_df_full.columns:
                                batch_df_full[col] = batch_X_mapped_user[col]

                        batch_scaled_full = scaler.transform(batch_df_full)
                        batch_scaled_df = pd.DataFrame(batch_scaled_full, index=batch_df_full.index, columns=required_features_for_scaler)
                        final_batch_for_model = batch_scaled_df[st.session_state['selected_features']]
                        st.session_state['final_batch_for_model'] = final_batch_for_model

                        batch_predictions_encoded = model.predict(final_batch_for_model)
                        batch_predictions_label = le.inverse_transform(batch_predictions_encoded)

                        batch_df_results = batch_df_raw.loc[final_batch_for_model.index].copy()
                        batch_df_results['Predicted_Label'] = batch_predictions_label
                        batch_df_results['åˆ†æçµæœ'] = batch_df_results['Predicted_Label'].apply(lambda x: 'æ”»æ“Š' if x != 'Benign' else 'æ­£å¸¸')
                        st.session_state['batch_results_df'] = batch_df_results

        except Exception as e:
            st.error(f"è™•ç†ä¸Šå‚³æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            if 'batch_results_df' in st.session_state:
                del st.session_state['batch_results_df']

        # --- Display Results ---
        if 'batch_results_df' in st.session_state:
            batch_df_results = st.session_state['batch_results_df']
            
            st.subheader("ğŸ“Š åˆ†æçµæœç¸½è¦½")
            prediction_counts = batch_df_results['åˆ†æçµæœ'].value_counts()
            st.bar_chart(prediction_counts)

            st.subheader("ğŸ“„ è©³ç´°åˆ†æçµæœ")
            filter_option = st.radio(
                "ç¯©é¸é¡¯ç¤ºçµæœï¼š",
                ('é¡¯ç¤ºå…¨éƒ¨', 'åƒ…é¡¯ç¤ºæ”»æ“Š', 'åƒ…é¡¯ç¤ºæ­£å¸¸'),
                horizontal=True,
                key='filter_radio'
            )

            if filter_option == 'åƒ…é¡¯ç¤ºæ”»æ“Š':
                filtered_df = batch_df_results[batch_df_results['åˆ†æçµæœ'] == 'æ”»æ“Š']
            elif filter_option == 'åƒ…é¡¯ç¤ºæ­£å¸¸':
                filtered_df = batch_df_results[batch_df_results['åˆ†æçµæœ'] == 'æ­£å¸¸']
            else:
                filtered_df = batch_df_results

            if not filtered_df.empty:
                st.dataframe(filtered_df)
                csv_results = filtered_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ç›®å‰çš„åˆ†æçµæœ",
                    data=csv_results,
                    file_name="traffic_analysis_results.csv",
                    mime="text/csv"
                )

            # --- SHAP Drill-down ---
            st.subheader("ğŸ”¬ æ·±å…¥åˆ†æå–®ç­†æ”»æ“Šæµé‡ (SHAP Drill-down)")
            attack_df = batch_df_results[batch_df_results['åˆ†æçµæœ'] == 'æ”»æ“Š']
            if attack_df.empty:
                st.info("åœ¨ç›®å‰çš„åˆ†æçµæœä¸­ï¼Œæ²’æœ‰åµæ¸¬åˆ°æ”»æ“Šæµé‡å¯ä¾›æ·±å…¥åˆ†æã€‚")
            else:
                selected_index = st.selectbox(
                    "é¸æ“‡ä¸€ç­†æ”»æ“Šæµé‡çš„ç´¢å¼• (Index) é€²è¡Œåˆ†æï¼š",
                    options=attack_df.index
                )

                if selected_index is not None:
                    with st.spinner("æ­£åœ¨ç‚ºæ‚¨é¸æ“‡çš„æµé‡ç”¢ç”Ÿ SHAP åˆ†æ..."):
                        try:
                            explainer = st.session_state['shap_explainer']
                            final_batch_for_model = st.session_state['final_batch_for_model']
                            le = st.session_state['le']

                            single_instance = final_batch_for_model.loc[[selected_index]]
                            single_prediction_label = batch_df_results.loc[selected_index, 'Predicted_Label']
                            single_prediction_index = list(le.classes_).index(single_prediction_label)

                            shap_values = explainer.shap_values(single_instance)
                            
                            base_value = explainer.expected_value
                            if isinstance(base_value, (list, np.ndarray)):
                                if single_prediction_index < len(base_value):
                                    shap_base_value = base_value[single_prediction_index]
                                else:
                                    shap_base_value = base_value[0]
                            else:
                                shap_base_value = base_value

                            if isinstance(shap_values, list):
                                if single_prediction_index < len(shap_values):
                                    shap_values_for_class = shap_values[single_prediction_index]
                                else:
                                    shap_values_for_class = shap_values[0]
                            else:
                                if single_prediction_index == 0:
                                    shap_values_for_class = -shap_values
                                else:
                                    shap_values_for_class = shap_values
                                    
                            shap_values_for_class = shap_values_for_class.flatten()

                            features_for_plot = single_instance.iloc[0]
                            if len(shap_values_for_class) == len(features_for_plot) + 1:
                                shap_values_for_class = shap_values_for_class[:-1]

                            summary_text = generate_shap_summary(
                                shap_values_for_class, 
                                single_instance,
                                single_prediction_label,
                                le,
                                shap_base_value
                            )
                            st.markdown(summary_text)
                        except KeyError:
                            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼šç„¡æ³•åœ¨å·²è™•ç†çš„è³‡æ–™ä¸­æ‰¾åˆ°ç´¢å¼• {selected_index}ã€‚")
                        except Exception as e:
                            st.warning(f"ç„¡æ³•ç”¢ç”Ÿ SHAP åˆ†æï¼š{e}")